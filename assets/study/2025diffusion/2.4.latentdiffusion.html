<!DOCTYPE HTML>
<html>
	<head>
		<title>Ziseok Lee</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../../../assets/css/main.css" />
		<!-- Favicon (use SVG with PNG fallback) -->
		<link rel="icon" href="../../../assets/images/lovebulb_rounded.svg" type="image/svg+xml">
		<link rel="icon" href="../../../assets/images/lovebulb_rounded_png.png" type="image/png">
		<!-- For apple touch and Android icons, it's better to use PNG -->
		<link rel="apple-touch-icon" href="../../../assets/images/lovebulb_rounded_png.png">
	</head>

	<body class="is-preload">
		<!-- Header -->
		<header id="header">
			<div class="inner">
				<a href="../../lovebulb/"><img src="../../../assets/images/lovebulb_rounded.svg" /></a>
				<p><a href="../../../index.html">HOME</a></p>
				<p><a href="../../../bio.html">BIO</a></p>
				<p><a href="../../../news.html">NEWS</a></p>
				<p><a href="../../../publications.html">PUBLICATIONS</a></p>
				<p><a href="https://aibl.snu.ac.kr/team">TEAM</a></p>
				<p><a href="../">STUDY</a></p>
			</div>
		</header>






		<!-- Main Division -->
		<div id="main">
			<!-- HOME -->
			<section>
                <h1>Advanced Sampling in Diffusion Models</h1>
                <hr>

				<p>
					This post continues our exploration of diffusion model sampling, diving into <strong>numerical samplers</strong> (Euler, Heun, Runge–Kutta, DPM-Solver), <strong>classifier-free guidance (CFG)</strong> and its interpretations, and <strong>latent diffusion</strong>. 
					We connect practical algorithms to theoretical principles, providing a rigorous yet intuitive understanding.
				</p>

				<hr />

				<h2>1. Numerical Solvers for SDEs and ODEs</h2>

				<p>
					Sampling from diffusion models amounts to integrating either:
				</p>

				<ul>
					<li><strong>Stochastic differential equations (SDEs)</strong> — DDPM-style sampling</li>
					<li><strong>Deterministic ODEs</strong> (probability flow ODEs) — DDIM-style sampling</li>
				</ul>

				<p>
					These can be integrated using numerical methods:
				</p>

				<ul>
					<li><strong>Euler–Maruyama</strong> (for SDEs): explicit, fast but low accuracy.</li>
					<li><strong>Heun’s method</strong> (2nd-order Runge–Kutta): corrects Euler with a predictor–corrector step.</li>
					<li><strong>DPM-Solver</strong>: an efficient high-order sampler designed for score-based diffusion ODEs.
					See the paper <a href="https://arxiv.org/abs/2206.00927">DPM-Solver</a> for the full derivation.
					</li>
				</ul>

				<p>
					The key benefit of advanced solvers like DPM-Solver is <strong>few-step sampling</strong> with high fidelity,
					thanks to treating the score model as a time-dependent vector field and integrating it as an ODE.
				</p>

				<h2>2. Classifier-Free Guidance (CFG)</h2>

				<p>
					In conditional generation, we want to sample from \( p(\mathbf{x} \mid \mathbf{y}) \). One option is <strong>classifier guidance</strong> (Dhariwal & Nichol, 2021), using a pretrained classifier \( \nabla_{\mathbf{x}} \log p(\mathbf{y} \mid \mathbf{x}) \). But CFG takes a simpler approach:
				</p>

				<ul>
					<li>Train a single conditional score model \( s_\theta(\mathbf{x}, t, \mathbf{y}) \),</li>
					<li>Use null-conditioning \( \varnothing \) during training with some probability (e.g., 10–20%)</li>
					<li>At inference, guide with:
					\[
					\tilde{s}_\theta(\mathbf{x}, t, \mathbf{y}) = (1 + w) s_\theta(\mathbf{x}, t, \mathbf{y}) - w s_\theta(\mathbf{x}, t, \varnothing)
					\]
					where \( w > 0 \) is the guidance scale.
					</li>
				</ul>

				<h3>Interpretation 1: Directional Control</h3>

				<p>
					This linear interpolation increases the gradient magnitude in the direction of the conditional score,
					amplifying the drift toward high-likelihood samples under \( p(\mathbf{x} \mid \mathbf{y}) \).
				</p>

				<h3>Interpretation 2: Annealed Denoising</h3>

				<p>
					As noted in GLIDE and subsequent works, CFG acts as an annealing mechanism: 
					the model gradually shifts from unconditional to conditional generation.
				</p>

				<h3>Interpretation 3: A Model vs. Its Noisy Self</h3>

				<p>
					CFG can also be seen as the model comparing itself to a "bad version" — the unconditional variant —
					and refining its outputs based on that discrepancy.
				</p>

				<p>
					CFG is especially powerful in <strong>text-to-image models</strong> like Stable Diffusion, where 
					nuanced conditioning (e.g., CLIP embeddings) allows for fine-grained generation control.
				</p>

				<h2>3. Latent Diffusion Models (LDM)</h2>

				<p>
					Training a diffusion model in pixel space is costly. <strong>Latent Diffusion Models</strong> (Rombach et al., 2022) propose:
				</p>

				<ul>
					<li>Train an autoencoder \( E(\mathbf{x}) = \mathbf{z} \), \( D(\mathbf{z}) = \hat{\mathbf{x}} \)</li>
					<li>Train a diffusion model in the latent space \( \mathbf{z} \in \mathbb{R}^d \) with \( d \ll HW \)</li>
					<li>Sample in latent space and decode to image</li>
				</ul>

				<p>
					Formally, diffusion is applied to \( \mathbf{z}_0 \sim E(p_{\text{data}}) \), and the generative model is:
				</p>

				\[
				p(\mathbf{x}) = \int p(\mathbf{x} \mid \mathbf{z}_0) p(\mathbf{z}_0) \, d\mathbf{z}_0
				\]

				<p>
					The benefit is computational: both training and sampling are dramatically cheaper in the latent space,
					and high-frequency details are preserved via decoder upsampling.
				</p>

				<p>
					Note that conditioning (e.g., text prompts) is often passed through CLIP or T5 embeddings,
					and cross-attended during sampling steps.
				</p>

				<h2>4. Summary</h2>

				<ul>
					<li><strong>Numerical samplers</strong> control quality–speed tradeoffs; DPM-Solver is among the most effective few-step solvers</li>
					<li><strong>Classifier-free guidance</strong> provides flexible and powerful conditioning with minimal overhead</li>
					<li><strong>Latent diffusion</strong> enables scalable generation by learning in compressed semantic spaces</li>
				</ul>

				<p>
					These ideas enable state-of-the-art image, audio, and video synthesis and are central to models like
					<strong>Stable Diffusion, Imagen, Midjourney, and Sora</strong>.
				</p>

				<p>In the next post, we may look at <em>guided sampling techniques</em> like classifier guidance, score distillation, and semantic control using additional modalities (e.g., keypoints, depth maps).</p>

			</section>
		</div>

		
		<!-- Footer -->
		<footer id="footer">
			<div class="inner">
				<ul class="icons">
					<li><a href="https://www.linkedin.com/in/ziseok-lee-b6a51734b" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
					<li><a href="https://github.com/ziseoklee" class="icon brands fa-github"><span class="label">Github</span></a></li>
					<li><a href="../../index.html#contact" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
				</ul>
				<ul class="copyright">
					<li>&copy; Ziseok Lee</li>
					<li><a href="http://html5up.net">HTML5 UP</a></li>
				</ul>
			</div>
		</footer>

		<script src="../../../assets/js/jquery.min.js"></script>
		<script src="../../../assets/js/jquery.poptrox.min.js"></script>
		<script src="../../../assets/js/browser.min.js"></script>
		<script src="../../../assets/js/breakpoints.min.js"></script>
		<script src="../../../assets/js/util.js"></script>
		<script src="../../../assets/js/main.js"></script>
		<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


	</body>
</html>