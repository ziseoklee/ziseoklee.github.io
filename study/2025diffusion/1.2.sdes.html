<!DOCTYPE HTML>
<html>
	<head>
		<title>Ziseok Lee</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../../assets/css/main.css" />
		<!-- Favicon (use SVG with PNG fallback) -->
		<link rel="icon" href="../../assets/images/lovebulb_rounded.svg" type="image/svg+xml">
		<link rel="icon" href="../../assets/images/lovebulb_rounded_png.png" type="image/png">
		<!-- For apple touch and Android icons, it's better to use PNG -->
		<link rel="apple-touch-icon" href="../../assets/images/lovebulb_rounded_png.png">
	</head>

	<body class="is-preload">
		<!-- Header -->
		<header id="header">
			<div class="inner">
				<a href="../../writing/"><img src="../../assets/images/lovebulb_rounded.svg" /></a>
				<p><a href="../../index.html">HOME</a></p>
				<p><a href="../../bio.html">BIO</a></p>
				<p><a href="../../news.html">NEWS</a></p>
				<p><a href="../../publications.html">PUBLICATIONS</a></p>
				<p><a href="https://aibl.snu.ac.kr/team">TEAM</a></p>
				<p><a href="../">STUDY</a></p>
			</div>
		</header>






		<!-- Main Division -->
		<div id="main">
			<!-- HOME -->
			<section>
                <h1>Stochastic Differential Equations and Fokker–Planck Equations</h1>
                <hr>

                <p>
                    In this post, we explore how stochastic differential equations (SDEs) give rise to the Fokker–Planck equations (FPEs), both in forward and backward form. These equations describe the time evolution of probability densities associated with stochastic processes, which is central to the theory of diffusion models in machine learning.
                </p>

                <h2>1. Stochastic Differential Equations (SDEs)</h2>

                <p>Consider a stochastic process \( X_t \in \mathbb{R}^d \) governed by the Itô SDE:</p>

                <p>
                \[
                dX_t = f(X_t, t)\,dt + g(X_t, t)\,dW_t
                \]
                </p>

                <p>
                where \( f : \mathbb{R}^d \times \mathbb{R} \to \mathbb{R}^d \) is the drift vector, \( g : \mathbb{R}^d \times \mathbb{R} \to \mathbb{R}^{d \times m} \) is the diffusion matrix, and \( W_t \) is an \( m \)-dimensional standard Wiener process.
                </p>

                <h2>2. Fokker–Planck Equation (Forward)</h2>

                <p>
                The Fokker–Planck (forward Kolmogorov) equation describes the evolution of the probability density \( p(x, t) \) of the process \( X_t \):
                </p>

                <p>
                \[
                \frac{\partial p}{\partial t} = -\nabla \cdot (f p) + \frac{1}{2} \sum_{i,j} \frac{\partial^2}{\partial x_i \partial x_j}\left( (D_{ij} p) \right)
                \]
                </p>

                <p>
                where \( D(x, t) = g(x, t)g(x, t)^\top \) is the diffusion tensor.
                </p>

                <h3>Proof Sketch (Itô to Fokker–Planck)</h3>

                <p>We derive the Fokker–Planck equation by applying Itô’s lemma to a smooth test function \( \phi(x) \) and computing the time derivative of the expectation:</p>

                <p>
                \[
                \frac{d}{dt} \mathbb{E}[\phi(X_t)] = \mathbb{E} \left[ \frac{\partial \phi}{\partial t} + \sum_i f_i \frac{\partial \phi}{\partial x_i} + \frac{1}{2} \sum_{i,j} D_{ij} \frac{\partial^2 \phi}{\partial x_i \partial x_j} \right]
                \]
                </p>

                <p>
                Using the identity \( \mathbb{E}[\phi(X_t)] = \int \phi(x) p(x, t)\, dx \) and integrating by parts, we match both sides and deduce the Fokker–Planck PDE for \( p(x, t) \).
                </p>

                <h2>3. Backward Kolmogorov Equation</h2>

                <p>
                Instead of tracking how \( p(x, t) \) evolves forward in time, the backward Kolmogorov equation looks at how the expected value of a future function evolves backward. For \( u(x, t) = \mathbb{E}_{x, t}[f(X_T)] \), it satisfies:
                </p>

                <p>
                \[
                \frac{\partial u}{\partial t} + f \cdot \nabla u + \frac{1}{2} \text{Tr}(D \nabla^2 u) = 0
                \]
                </p>

                <p>
                This PDE is used heavily in control theory and score-based diffusion models.
                </p>

                <h2>4. Anderson’s Theorem: Time Reversal of Diffusions</h2>

                <p>
                Suppose we observe a diffusion process \( X_t \) defined by:
                </p>

                <p>
                \[
                dX_t = f(X_t, t)\,dt + g\,dW_t
                \]
                </p>

                <p>
                with constant \( g \in \mathbb{R}^{d \times d} \), and \( p(x, t) \) the marginal density at time \( t \). Then the time-reversed process \( \tilde{X}_t := X_{T - t} \) also satisfies an SDE:
                </p>

                <p>
                \[
                d\tilde{X}_t = \left( f(\tilde{X}_t, T - t) - g g^\top \nabla_x \log p(\tilde{X}_t, T - t) \right) dt + g\,d\bar{W}_t
                \]
                </p>

                <p>
                where \( \bar{W}_t \) is a Wiener process under the time-reversed filtration.
                </p>

                <h3>Proof of Anderson’s Theorem</h3>

                <ul>
                <li>Let the original forward SDE be:
                \[
                dX_t = f(X_t, t)\,dt + g\,dW_t
                \]
                </li>

                <li>The Fokker–Planck equation for \( p(x, t) \) is:
                \[
                \frac{\partial p}{\partial t} = -\nabla \cdot (fp) + \frac{1}{2} \nabla \cdot (D \nabla p)
                \]
                with \( D = g g^\top \).
                </li>

                <li>Let \( \tilde{X}_t = X_{T - t} \). The backward transition probabilities must match the forward ones, so the backward drift \( \tilde{f} \) must satisfy:
                \[
                \tilde{f}(x, t) = f(x, T - t) - D \nabla_x \log p(x, T - t)
                \]
                </li>

                <li>Therefore, the reversed SDE is:
                \[
                d\tilde{X}_t = \left( f(\tilde{X}_t, T - t) - D \nabla_x \log p(\tilde{X}_t, T - t) \right)\,dt + g\,d\bar{W}_t
                \]
                </li>
                </ul>

                <p>
                The proof hinges on deriving the change in drift necessary to ensure that the reversed process yields the same marginals as the original. This result is key in score-based diffusion models, where the score \( \nabla \log p(x, t) \) is learned to run the reversed SDE to sample from a data distribution.
                </p>

                <h2>5. Applications in Diffusion Models</h2>

                <ul>
                <li><strong>Forward process:</strong> Adds Gaussian noise via a simple SDE (e.g., Variance Preserving SDE).</li>
                <li><strong>Reverse process:</strong> Uses learned scores \( s_\theta(x, t) \approx \nabla_x \log p(x, t) \) to guide denoising.</li>
                </ul>

                <p>
                Thanks to Anderson’s theorem, we can sample from complex data distributions by running the learned time-reversed SDE from noise to data — a foundation of diffusion-based generative models like DDPMs and ScoreSDEs.
                </p>

                <!-- <h2>1. Stochastic Differential Equations (SDEs)</h2>

                <p>
                    A general Itô SDE in \( \mathbb{R}^d \) is given by:
                </p>

                <p>
                    \[
                    dX_t = f(X_t, t)dt + g(X_t, t)dW_t,
                    \]
                </p>

                <p>
                    where:
                    <ul>
                    <li>\( X_t \in \mathbb{R}^d \): the state of the system at time \( t \),</li>
                    <li>\( f: \mathbb{R}^d \times \mathbb{R} \to \mathbb{R}^d \): the drift function,</li>
                    <li>\( g: \mathbb{R}^d \times \mathbb{R} \to \mathbb{R}^{d \times m} \): the diffusion coefficient,</li>
                    <li>\( W_t \in \mathbb{R}^m \): a standard \( m \)-dimensional Brownian motion.</li>
                    </ul>
                </p>

                <h2>2. The Forward Fokker–Planck Equation</h2>

                <p>
                    Let \( p(x, t) \) denote the probability density of \( X_t \). The forward Fokker–Planck equation describes how this density evolves over time:
                </p>

                <p>
                    \[
                    \frac{\partial p(x, t)}{\partial t} = -\sum_i \frac{\partial}{\partial x_i} \left[ f_i(x, t)p(x, t) \right]
                    + \frac{1}{2} \sum_{i,j} \frac{\partial^2}{\partial x_i \partial x_j} \left[ (D(x, t))_{ij}p(x, t) \right],
                    \]
                </p>

                <p>
                    where \( D(x, t) = g(x, t)g(x, t)^\top \) is the diffusion matrix.
                </p>

                <h3>Derivation Sketch (Itô–Stratonovich–Kolmogorov Forward Equation)</h3>

                <p>
                    From Itô’s lemma applied to a test function \( \phi(x) \), we get:
                </p>

                <p>
                    \[
                    d\phi(X_t) = \left( \sum_i f_i \frac{\partial \phi}{\partial x_i} + \frac{1}{2} \sum_{i,j} D_{ij} \frac{\partial^2 \phi}{\partial x_i \partial x_j} \right) dt + \text{martingale terms}.
                    \]
                </p>

                <p>
                    Taking expectation and using integration by parts gives the forward FPE.
                </p>

                <h2>3. The Backward Fokker–Planck Equation</h2>

                <p>
                    The backward Fokker–Planck equation (or Kolmogorov backward equation) governs the evolution of functionals of the process, e.g., \( u(x, t) = \mathbb{E}[\phi(X_T) | X_t = x] \). It reads:
                </p>

                <p>
                    \[
                    \frac{\partial u(x, t)}{\partial t} = -\sum_i f_i(x, t) \frac{\partial u}{\partial x_i}
                    - \frac{1}{2} \sum_{i,j} D_{ij}(x, t) \frac{\partial^2 u}{\partial x_i \partial x_j}.
                    \]
                </p>

                <p>
                    This PDE evolves backward in time from terminal condition \( u(x, T) = \phi(x) \).
                </p>

                <h2>4. Anderson's Theorem</h2>

                <p>
                    Anderson's theorem provides a condition under which the time reversal of a diffusion process remains Markovian and satisfies another SDE. Specifically, for an SDE:
                </p>

                <p>
                    \[
                    dX_t = f(X_t, t)dt + g(X_t, t)dW_t,
                    \]
                </p>

                <p>
                    under mild regularity and non-degeneracy conditions, the time-reversed process \( \tilde{X}_t = X_{T - t} \) also satisfies an SDE:
                </p>

                <p>
                    \[
                    d\tilde{X}_t = \tilde{f}(\tilde{X}_t, t)dt + g(\tilde{X}_t, t)d\tilde{W}_t,
                    \]
                </p>

                <p>
                    where \( \tilde{f}(x, t) \) involves gradients of the log-density \( \nabla_x \log p(x, t) \), often written in score-based modeling literature.
                </p>

                <h3>Relevance to Diffusion Models</h3>

                <p>
                    In generative modeling, we often interpret the backward SDE (or time-reversed FPE) as the generative process, where the reverse drift is adjusted using score functions \( \nabla_x \log p(x, t) \). This is a key idea in score-based diffusion models and algorithms like DDPM and SDE-based methods such as those in Song et al. (2021).
                </p>

                <h2>Conclusion</h2>

                <p>
                    Understanding the Fokker–Planck equations provides a foundational grasp of how probability flows under stochastic processes, and is essential to modern generative modeling with diffusion processes. The connection between SDEs, density dynamics, and time-reversal via Anderson’s theorem enables both theoretical understanding and practical algorithm design.
                </p> -->

				
			</section>
		</div>

		
		<!-- Footer -->
		<footer id="footer">
			<div class="inner">
				<ul class="icons">
					<li><a href="https://www.linkedin.com/in/ziseok-lee-b6a51734b" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
					<li><a href="https://github.com/ziseoklee" class="icon brands fa-github"><span class="label">Github</span></a></li>
					<li><a href="../../index.html#contact" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
				</ul>
				<ul class="copyright">
					<li>&copy; Ziseok Lee</li>
					<li><a href="http://html5up.net">HTML5 UP</a></li>
				</ul>
			</div>
		</footer>

		<script src="../../assets/js-strata/jquery.min.js"></script>
		<script src="../../assets/js-strata/jquery.poptrox.min.js"></script>
		<script src="../../assets/js-strata/browser.min.js"></script>
		<script src="../../assets/js-strata/breakpoints.min.js"></script>
		<script src="../../assets/js-strata/util.js"></script>
		<script src="../../assets/js-strata/main.js"></script>
		<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

	</body>
</html>